<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://goroyal.github.io</id>
    <title>Goroyal&apos;s blog</title>
    <updated>2020-08-02T15:03:24.883Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="http://goroyal.github.io"/>
    <link rel="self" href="http://goroyal.github.io/atom.xml"/>
    <subtitle>学习分享</subtitle>
    <logo>http://goroyal.github.io/images/avatar.png</logo>
    <icon>http://goroyal.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Goroyal&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[JVM内存溢出]]></title>
        <id>http://goroyal.github.io/post/jvm-nei-cun-yi-chu/</id>
        <link href="http://goroyal.github.io/post/jvm-nei-cun-yi-chu/">
        </link>
        <updated>2020-08-02T14:56:33.000Z</updated>
        <content type="html"><![CDATA[<p>JVM内存溢出经常有2种报错：</p>
<ul>
<li>OutOfMemory（OOM）</li>
<li>StackOverFlow（SOF ）</li>
</ul>
<p>除了程序计数器外，虚拟机内存的其他几个运行时区域都有发生OutOfMemoryError异常的可能。为了进行试验，在运行时使用以下的JVM参数：</p>
<pre><code>--verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8
</code></pre>
<h2 id="java堆溢出">Java堆溢出</h2>
<p>Java堆用于存储对象实例，只要不断地创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，那么在对象数量到达最大堆的容量限制后就会产生内存溢出异常。</p>
<pre><code class="language-java">/**
 * VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemorryError
 * 将对的最小值-Xms参数与最大值-Xmx参数设置为一样即可避免堆自动扩展，通过参数-XX:+HeapDumpOnOutOfMemorryError可以让虚拟机在出现内存溢出异常时Dump出当前的内存堆转储快照以便时候进行分析
 */
public class HeapOOM {
	static class OOMObject {
	}
	
	public static void main(String[] args){
		List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;();
		while(true){
			list.add(new OOMObject());
		}
	}
}
</code></pre>
<p>运行结果：</p>
<pre><code class="language-shell">java.lang.OutOfMemoryError: Java Heap space
Dumping heap to java_pid3404.hprof...
Heap dump file created[22045981 bytes in 0.663 secs]
</code></pre>
<p>Java堆内存的OOM异常是实际应用中常见的内存溢出异常情况。当出现Java堆内存溢出时，异常堆栈信息”java.lang.OutOfMemoryError“会跟着进一步提示”Java heap space“。</p>
<p>要解决这个区域的异常，一般的手段是先通过内存映像分析工具（如Eclipse Memory Analyzer）对Dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（<strong>Memory Leak</strong>）还是内存溢出（<strong>Memory Overflow</strong>）。</p>
<p>如果是内存泄露，可以进一步提高工具查看泄露对象到GC Roots的引用链。于是就能找到泄露对象是通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收它们的。掌握了泄露对象的类型信息以及GC Roots引用链的信息，就可以比较准确地定位出现泄露代码的位置。</p>
<p>如果不存在泄露，换句话说，就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。</p>
<h2 id="虚拟机栈和本地方法栈溢出">虚拟机栈和本地方法栈溢出</h2>
<p>由于在Hotspot虚拟机中并不区分虚拟机栈和本地方法栈，因此对于Hotspot来说，虽然-Xoss参数（用于设置本地方法栈大小）存在，但实际上是无效的。栈容量只由-Xss参数设定。在Java虚拟机规范中描述了两种异常：</p>
<ul>
<li>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。</li>
<li>如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。</li>
</ul>
<p>这里把异常分成两种情况，看似更加严谨，但却存在一些互相重叠的地方：当栈空间无法继续分配时，到底是内存太小，还是已使用的栈空间太大，其本质上是对同一件事情的两种描述而已。</p>
<p>在《深入理解Java虚拟机规范》作者的实验中，将实验范围限制于单线程中的操作，尝试了两种方法均无法让虚拟机产生OutOfMemoryError异常，尝试的结果都是StackOverflowError。</p>
<ul>
<li>使用-Xss参数减少栈内存容量。结果，抛出StackOverflowError异常，异常出现时输出的堆栈深度相应地缩小。</li>
<li>定义了大量的本地变量，增大此方法帧中本地变量表的长度。结果：抛出StackOverflowError异常时输出的堆栈深度相应缩小。</li>
</ul>
<pre><code class="language-java">/**
 * VM args: -Xss128k
 */
public class JavaVMStackOF {
	private int stackLength = 1;
	
	public void stackLeak() {
		stackLength++;
		stackLeak();
	}
	
	public static void main(String[] args) throws Throwable {
		JavaVMStackSOF oom = new JavaVMStackSOF();
		try {
			oom.stackLeak();
		} catch (Throwable e){
			System.out.println(&quot;stack length:&quot; + oom.stackLength);
			throw e;
		}
	}
}
</code></pre>
<p>运行结果：</p>
<pre><code class="language-shell">stack length: 2402
Exception in thread &quot;main&quot; java.lang.StackOverflowError
	at....
.....后续异常堆栈信息省略
</code></pre>
<p>实验结果表明：在单个线程下，无论是由于栈帧太大还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是StackOverflowError异常。<br>
如果测试时不限于单线程，通过不断地建立线程的方式倒是可以产生内存溢出异常。但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系。或者准确地说，在这种情况下，为每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。<br>
这一点需要在开发多线程应用时特别注意，出现StackOverflowError异常时有错误堆栈可以阅读，相对来说，比较容易找到问题的所在。而且，如果使用虚拟机默认参数，栈深度在大多数情况下（因为每个方法压入栈的帧大小并不是一样的，所以只能说大多数情况下）达到1000~2000完全没有问题。但是如果是建立过多线程导致的内存溢出，在不能减少线程数或者更换64位虚拟机的情况下，就只能通过减少最大堆和减少栈容量来换取更多的线程。如果没有这方面的处理经验，<strong>这种通过”减少内存“的手段来解决内存溢出的方式会比较难以想到</strong>。</p>
<pre><code class="language-java">public class JavaVMStackOOM {
	private void dontStop() {
		while (true) {}
	}
	
	public void stackLeakByThread() {
		while(true) {
			Thread thread = new Thread(new Runnable() {
				@Override
				public void run() {
					dontStop();
				}
			});
			thread.start();
		}
	}
	public static void main(String[] args) throws Throwable {
		JavaVMStackOOM oom = new JavaVMStackOOM();
		oom.stackLeakByThread();
	}
}
</code></pre>
<h2 id="方法区和运行时常量池溢出">方法区和运行时常量池溢出</h2>
<p>JDK 1.7开始逐步”去永久代“，此处顺便看看这件事情的实际影响。<br>
String.intern()是一个Native方法，作用是：如果字符串常量池中已经包含一个等于此String对象的字符串，则返回代表池中这个字符串的String对象；否则将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。在JDK 1.6及之前的版本中，由于常量池分配在永久代内，我们可以通过-XX:PermSize和-XX:MaxPermSize限制方法区大小，从而间接限制其中常量池的容量。</p>
<pre><code class="language-java">/**
 * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M
 */
public class RuntimeConstantPoolOOM {
	public static void main(String[] args) {
		// 使用List保持着常量池引用，避免Full GC回收常量池行为
		List&lt;String&gt; list = new ArrayList&lt;&gt;();
		// 10MB的PermSize在integer范围内足够产生OOM了
		int i = 0;
		while (true) {
			list.add(String.valueOf(i++).intern());
		}
	}
}
</code></pre>
<p>运行结果：</p>
<pre><code class="language-shell">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space
	at java.lang.String.intern(Native Method)
	at ... 
</code></pre>
<p>从运行结果可以看到，运行时常量池溢出，在OutOfMemoryError后面跟随的提示信息是”PermGen space“，说明运行时常量池属于方法区（Hotspot虚拟机中的永久代）的一部分。</p>
<p>而使用JDK 1.7运行这段程序就不会得到相同的结果，while循环将一直进行下去。关于这个字符串常量池的实现问题，还可以引申出一个更有意思的影响：</p>
<pre><code class="language-java">public class RuntimeConstantsPoolOOM {
	public static void main(String[] args){
		String str1 = new StringBuilder(&quot;计算机&quot;).append(&quot;软件&quot;).toString();
		System.out.println(str1.intern() == str1);
		
		String str2 = new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString();
		System.out.println(str2.intern() == str2);
	}
} 
</code></pre>
<p>这段代码在JDK 1.6中运行，会得到两个false；而在JDK 1.7中运行会得到一个true一个false。产生差异的原因是：JDK 1.6中，<code>intern()</code>方法会把所赐遇到的字符串实例复制到永久代中，返回的也是永久代总这个字符串实例的引用，而由StringBuilder创建的字符串实例在Java堆上，所以必然不是同一个引用，将返回false。<br>
而在JDK 1.7中的<code>intern()</code>实现不会再复制实例，只是在常量池中记录首次出现的实例引用，因此<code>intern()</code>返回的引用和由StringBuilder创建的那个字符串实例是同一个。对str2比较返回false是因为&quot;java&quot;这个字符串在执行StringBuilder.toString()之前已经出现过，字符串常量中已经有它的引用额，不符合”首次出现“的原则，而”计算机软件“这个字符串则是首次出现的。</p>
<p>方法区用于存放Class的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。当前的很多主流框架如Spring、Hibernate对类进行增强时都会使用到CGLib这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的Class可以加载入内存。像大量反射、大量JSP文件或动态产生JSP文件的应用、基于OSGi的应用（即使是同一个类文件，被不同的加载器加载也会视为不同的类）也会需要较大的方法区保证。</p>
<h2 id="本机直接内存溢出">本机直接内存溢出</h2>
<p>DirectMemory容量可以通过<code>-XX:MaxDirectMemory</code>指定，如果不指定则默认与Java堆最大值一样。如下代码越过了DirectByBuffer类，直接通过反射获取Unsafe实例进行内存分配（Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例，也就是设计者希望只有rt.jar中的类才能使用Unsafe的功能）。因为虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申请分配内存，而是通过计算得知内存无法分配于是手动抛出异常，真正申请分配内存的方法是<code>unsafe.allocateMemory()</code>。</p>
<pre><code class="language-java">/**
 * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M
 */
public class DirectMemoryOOM {
	private static final int _1MB = 1024 * 1024;
	
	public static void main(String[] args) throws Exception {
		Field unsafeField = Unsafe.class.getDeclaredFields()[0];
		unsafeField.setAccessible(true);
		Unsafe unsafe = (Unsafe) unsafeField.get(null);
		while(true) {
			unsafe.allocateMemory(_1MB);
		}
	}
}
</code></pre>
<p>运行结果：</p>
<pre><code class="language-shell">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError
	at ...
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JVM GC]]></title>
        <id>http://goroyal.github.io/post/jvm-gc/</id>
        <link href="http://goroyal.github.io/post/jvm-gc/">
        </link>
        <updated>2020-08-02T14:49:41.000Z</updated>
        <content type="html"><![CDATA[<h2 id="引用计数法">引用计数法</h2>
<p>给对象中添加一个引用计数器，每当有一个地方引用它时，计数器就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。<br>
客观地说，引用计数算法（Reference Counting）的实现简单，判定效率也很高，在大部分情况下他都是一个不错的算法）。<br>
但是至少主流的Java虚拟机里没有选用该方法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。</p>
<h2 id="可达性分析算法">可达性分析算法</h2>
<p>这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。</p>
<p>在Java语言中，可作为GC Roots的对象包括下面几种：</p>
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象</li>
<li>方法区中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈中JNI（即一般说的Native方法）引用的对象</li>
</ul>
<h2 id="标记-清除算法">标记-清除算法</h2>
<p>首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。</p>
<p>它是最基础的收集算法，后续的收集算法都是基于这种思路并对其不足进行改进而得到的。</p>
<p>它的主要不足有两个：</p>
<ul>
<li>效率问题，标记和清除两个过程的效率都不高</li>
<li>空间问题，会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</li>
</ul>
<h2 id="复制算法">复制算法</h2>
<p>为了解决效率问题，一种称为”复制“的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。</p>
<p>这种算法的代价是将内存缩小为原来的一半，未免太高了一点。</p>
<p>现在的商业虚拟机都采用这种收集算法来回收新生代。IBM公司的专门研究表明，新生代中的对象98%是”朝生夕死“的，所以不需要按照1：1的比例来划分内存空间，而是将一块内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。Hotspot虚拟机默认Eden和Survivor大小比例是8：1。</p>
<p>当然，我们也没有办法保证每次回收都只有不多于10%对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。</p>
<h2 id="标记-整理算法">标记-整理算法</h2>
<p>复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。</p>
<p>根据老年代的特点，有人提出标记-整理算法，标记过程仍然与”标记-清除“算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。</p>
<h2 id="分代收集算法">分代收集算法</h2>
<p>当前商业虚拟机的垃圾收集都采用”分代收集“算法，这种算法根据对象存活周期的不同将内存分为几块。一般是把Java堆分为新生代和老生代。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java内存模型]]></title>
        <id>http://goroyal.github.io/post/java-memory-model/</id>
        <link href="http://goroyal.github.io/post/java-memory-model/">
        </link>
        <updated>2020-08-02T14:47:54.000Z</updated>
        <content type="html"><![CDATA[<p>在多核系统中，处理器一般有一层或者多层的缓存，这些的缓存通过加速数据访问（因为数据距离处理器更近）和降低共享内存在总线上的通讯（因为本地缓存能够满足很多内存操作）来提高CPU性能。缓存能够大大提升性能，但是它们也带来了许多挑战。例如，当两个CPU同时检查相同的内存地址时会发生什么？在什么样的条件下它们会看到相同的值？</p>
<p>在处理器层面上，内存模型定义了一个充要条件：“让当前的处理器可以看到其他的处理器写入到内存数据”以及“其他处理器可以看到当前处理器写入到内存的数据”。有些处理器有很强的内存模型（strong memory model），能够让所有的处理器在任何时候任何指定的内存地址上都可以看到完全相同的值。而另外一些处理器则有较弱的内存模型（weaker memory model），在这种处理器中，必须使用内存屏障（一种特殊的指令）来刷新本地处理器缓存并使本地处理器缓存无效，目的是为了让当前处理器能够看到其他处理器的写操作或者让其他处理器能看到当前处理器的写操作。这些内存屏障通常在lock和unlock操作的时候完成。内存屏障在高级语言中对程序员是不可见的。</p>
<p>在强内存模型下，有时候编写程序可能会更容易，因为减少了对内存屏障的依赖。但是即使在一些最强的内存模型下，内存屏障仍然是必须的。设置内存屏障往往与我们的直觉并不一致。进来处理器设计的趋势更倾向于弱的内存模型，因为弱内存模型削弱了缓存一致性，所以在多处理器平台和更大容量的内存下可以实现更好的可伸缩性。</p>
<p>“一个线程的写操作对其他线程可见”这个问题是因为编译器对代码进行重排序导致的。例如，只要代码移动不会改变程序的语义，当编译器认为程序中移动一个写操作到后面会更有效的时候，编译器就会对代码进行移动。如果编译器推迟执行一个操作，其他线程可能在这个操作执行完之前都不会看到该操作的结果，这反应了缓存的影响。</p>
<p>此外，写入内存的操作能够被移动到程序里更前的时候。在这种情况下，其他的线程在程序中可能看到一个比它实际发生更早的写操作。所有的这些灵活性的设计是为了通过给编译器，运行时或硬件灵活性使其性能在最佳顺序的情况下来执行操作。在内存模型的限定之内，我们能够获取到更高的性能。</p>
<h2 id="哪个区域存放哪些内容">哪个区域存放哪些内容</h2>
<ul>
<li>方法区：各个线程的共享区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。习惯在Hotspot虚拟机上的开发者很多人把方法区成为“永久代”。</li>
<li>虚拟机栈：线程私有的，描述的是Java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口灯信息。每一个方法从调研直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。局部变量表存放了编译器可知的各种基本数据类型、对象引用和redurnAddress类型。如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。</li>
<li>本地方法栈：与虚拟机栈类似，但是本地方法栈为虚拟机使用到的Native方法服务。</li>
<li>堆：对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一的目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。是垃圾收集器管理的主要区域。</li>
<li>程序计数器：一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。</li>
<li>直接内存：直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现。JDK 1.4中新加入了NIO类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java volatile]]></title>
        <id>http://goroyal.github.io/post/java-volatile/</id>
        <link href="http://goroyal.github.io/post/java-volatile/">
        </link>
        <updated>2020-08-02T11:28:35.000Z</updated>
        <content type="html"><![CDATA[<h2 id="volatile语义">volatile语义</h2>
<p>一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：</p>
<ul>
<li>保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。</li>
<li>禁止进行指令重排序。</li>
</ul>
<p>看一段代码：</p>
<pre><code class="language-java">public class VolatileExample extends Thread{
    //设置类静态变量,各线程访问这同一共享变量
    private  static boolean flag = false;
    //无限循环,等待flag变为true时才跳出循环
   public void run() {
       while (!flag){
       };
       System.out.println(&quot;停止了&quot;);
   }

    public static void main(String[] args) throws Exception {
        new VolatileExample().start();
        //sleep的目的是等待线程启动完毕,也就是说进入run的无限循环体了
        Thread.sleep(100);
        flag = true;
    }
}
</code></pre>
<p>当把上面代码中变量flag改成下面这样：</p>
<pre><code class="language-java">private  static valotile boolean flag = false;
</code></pre>
<p>在执行的话，你就会发现打印了“停止了”信息，因为用volatile修饰之后就变得不一样了：</p>
<ul>
<li>第一：使用volatile关键字会强制将修改的值立即写入主存；</li>
<li>第二：使用volatile关键字的话，当线程main进行修改时，会导致线程那么线程VolatileExample的工作内存中缓存变量flag的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；</li>
<li>第三：由于线程那么线程VolatileExample的工作内存中缓存变量flag的缓存行无效，所以线程那么线程VolatileExample再次读取变量flag的值时会去主存读取。</li>
</ul>
<p>那么在线程main修改flag值时（当然这里包括2个操作，修改线程main工作内存中的值，然后将修改后的值写入内存），会使得线程VolatileExample的工作内存中缓存变量flag的缓存行无效，然后线程读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。</p>
<p>那么线程VolatileExample读取到的就是最新的正确的值。<br>
使用volatile关键字增加了实例变量在多个线程之间的可见性。但是volatile关键字最致命的缺点是不支持原子性。</p>
<p>下面将关键字synchronized和volatile进行一下比较：</p>
<ol>
<li>关键字volatile是线程同步的轻量级实现，所以volatile性能肯定比synchronized要好，并且volatile只能修饰于变量，而synchronized可以修饰方法，以及代码块。随着JDK新版本的发布，synchronized关键字在执行效率上得到很大提升，在开发中使用synchronized关键字的比率还是比较大的。</li>
<li>多线程访问volatile不会发生阻塞，而synchronized会出现阻塞。</li>
<li>volatile能保证数据的可见性，但不能保证原子性；而synchronized可以保证原子性，也可以间接保证可见性，因为它将私有内存和公共内存中的数据做同步。</li>
<li>再次重申一下，关键字volatile解决的是变量在多个线程之间的可见性；而synchronized关键字解决的是多个线程之间访问资源的同步性。</li>
</ol>
<h2 id="volatile非原子的特性">volatile非原子的特性</h2>
<p>从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？<br>
下面看一个例子：</p>
<pre><code class="language-Java">public class Test {
    public volatile int inc = 0;
     
    public void increase() {
        inc++;
    }
     
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
         
         //保证前面的线程都执行完
        while(Thread.activeCount()&gt;1)
   			Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<p>也许有些朋友认为输出结果是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。可能有人会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。</p>
<p>这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。</p>
<p>在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：</p>
<p>假如某个时刻变量inc的值为10，线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；</p>
<p>然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值是10，然后进行加1操作，并把11写入工作内存，最后写入主存。</p>
<p>然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。</p>
<p>那么两个线程分别进行了一次自增操作后，inc只增加了1。</p>
<p>虽然happens-before规则中的volatile变量规则是保证一个变量在修改volatile变量时，会让缓存行无效吗，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。</p>
<p><strong>根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。</strong></p>
<p>把上面的代码改成以下任何一种都可以达到效果：<br>
采用synchronized：</p>
<pre><code class="language-java">public class Test {
    public  int inc = 0;
    
    public synchronized void increase() {
        inc++;
    }
    
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
        
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<p>采用Lock：</p>
<pre><code class="language-java">public class Test {
    public  int inc = 0;
    Lock lock = new ReentrantLock();
    
    public  void increase() {
        lock.lock();
        try {
            inc++;
        } finally{
            lock.unlock();
        }
    }
    
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
        
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<p>采用AtomicInteger：</p>
<pre><code class="language-Java">public class Test {
    public  AtomicInteger inc = new AtomicInteger();
     
    public  void increase() {
        inc.getAndIncrement();
    }
    
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
        
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<p>在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。</p>
<h2 id="volatile能保证有序性">volatile能保证有序性</h2>
<p>在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。</p>
<p>volatile关键字禁止指令重排序有两层意思：<br>
1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；</p>
<p>2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。<br>
可能上面说的比较绕，举个简单的例子：</p>
<pre><code class="language-Java">//x、y为非volatile变量
//flag为volatile变量
 
x = 2;        //语句1
y = 0;        //语句2
flag = true;  //语句3
x = 4;         //语句4
y = -1;       //语句5
</code></pre>
<p>由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。</p>
<h2 id="volatile的原理和实现机制">volatile的原理和实现机制</h2>
<p>前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。</p>
<p>下面这段话摘自《深入理解Java虚拟机》：</p>
<blockquote>
<p>观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令。<br>
lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：</p>
<ul>
<li>它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；</li>
<li>它会强制将对缓存的修改操作立即写入主存；</li>
<li>如果是写操作，它会导致其他CPU中对应的缓存行无效。</li>
</ul>
</blockquote>
<h2 id="总结">总结</h2>
<p>synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：</p>
<ul>
<li>对变量的写操作不依赖于当前值</li>
<li>该变量没有包含在具有其他变量的不变式中</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java 线程中的3个特性]]></title>
        <id>http://goroyal.github.io/post/java-thread-feature/</id>
        <link href="http://goroyal.github.io/post/java-thread-feature/">
        </link>
        <updated>2020-08-02T11:22:08.000Z</updated>
        <content type="html"><![CDATA[<h2 id="原子性">原子性</h2>
<p>在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。<br>
上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i：<br>
请分析以下哪些操作是原子性操作：</p>
<pre><code class="language-java">x = 10;         //语句1
y = x;         //语句2
x++;           //语句3
x = x + 1;     //语句4
</code></pre>
<p>咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。</p>
<p>语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。所以上面4个语句只有语句1的操作具备原子性。</p>
<p>也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。</p>
<p>不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。</p>
<p>从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。</p>
<h2 id="可见性">可见性</h2>
<p>对于可见性，Java提供了<code>volatile</code>关键字来保证可见性。</p>
<p>当一个共享变量被<code>volatile</code>修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。</p>
<p>而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。</p>
<p>另外，通过<code>synchronized</code>和<code>Lock</code>也能够保证可见性，<code>synchronized</code>和<code>Lock</code>能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。</p>
<h2 id="有序性">有序性</h2>
<p>在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。<br>
在Java里面，可以通过<code>volatile</code>关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过<code>synchronized</code>和<code>Lock</code>来保证有序性，很显然，<code>synchronized</code>和<code>Lock</code>保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。</p>
<p>另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。</p>
<h3 id="happens-before原则先行发生原则">happens-before原则（先行发生原则）</h3>
<ul>
<li>程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作</li>
<li>锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作</li>
<li>volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作</li>
<li>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C</li>
<li>线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作</li>
<li>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生</li>
<li>线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行</li>
<li>对象终结规则：一个对象的初始化完成先行发生于它的<code>finalize()</code>方法的开始</li>
</ul>
<p>这8条原则摘自《深入理解Java虚拟机》。<br>
这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。</p>
<p>下面我们来解释一下前4条规则：<br>
对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。</p>
<p>第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。</p>
<p>第三条规则是一条比较重要的规则，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。</p>
<p>第四条规则实际上就是体现happens-before原则具备传递性。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java锁]]></title>
        <id>http://goroyal.github.io/post/java-lock/</id>
        <link href="http://goroyal.github.io/post/java-lock/">
        </link>
        <updated>2020-08-02T09:34:40.000Z</updated>
        <content type="html"><![CDATA[<h2 id="锁状态">锁状态</h2>
<p>Java中锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</p>
<p><strong>锁自旋</strong><br>
我们知道在当某个线程在进入同步方法/代码块时若发现该同步方法/代码块被其他现在所占，则它就要等待，进入阻塞状态，这个过程性能是低下的。</p>
<p>在遇到锁的争用或许等待事，线程可以不那么着急进入阻塞状态，而是等一等，看看锁是不是马上就释放了，这就是锁自旋。锁自旋在一定程度上可以对线程进行优化处理。</p>
<p><strong>偏向锁</strong><br>
偏向锁主要为了解决在没有竞争情况下锁的性能问题。在大多数情况下锁锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当某个线程获得锁的情况，该线程是可以多次锁住该对象，但是每次执行这样的操作都会因为CAS（CPU的Compare-And-Swap指令）操作而造成一些开销消耗性能，为了减少这种开销，这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。</p>
<p>当有其他线程在尝试着竞争偏向锁时，持有偏向锁的线程就会释放锁。</p>
<p><strong>锁膨胀</strong><br>
多个或多次调用粒度太小的锁，进行加锁解锁的消耗，反而还不如一次大粒度的锁调用来得高效。</p>
<p><strong>轻量级锁</strong><br>
轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。轻量级锁在当前线程的栈帧中建立一个名为锁记录的空间，用于存储锁对象目前的指向和状态。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁会比传统的重量级锁更慢。</p>
<h2 id="加锁方式">加锁方式</h2>
<p>在使用synchronized时，我们是这样使用锁的：</p>
<pre><code class="language-java">public class ThreadTest {
    public void test(){
        synchronized(this){
            //do something
        }
    }
}
</code></pre>
<p>synchronized可以确保在同一时间内只有一个线程在执行dosomething。下面是使用lock替代synchronized：</p>
<pre><code class="language-java">public class ThreadTest {
    Lock lock = new Lock();
    public void test(){
        lock.lock();
        //do something
        lock.unlock();
    }
}
</code></pre>
<p>lock()方法会对Lock实例对象进行加锁，因此所有对该对象调用lock()方法的线程都会被阻塞，直到该Lock对象的unlock()方法被调用。</p>
<h2 id="锁的公平性">锁的公平性</h2>
<p>公平性的对立面是饥饿。那么什么是“饥饿”呢？如果一个线程因为其他线程在一直抢占着CPU而得不到CPU运行时间，那么我们就称该线程被“饥饿致死”。而解决饥饿的方案则被称之为“公平性”——所有线程均可以公平地获得CPU运行机会。</p>
<p>导致线程饥饿主要有如下几个原因：<br>
高优先级线程吞噬所有的低优先级线程的CPU时间。我们可以为每个线程单独设置其优先级，从1到10。优先级越高的线程获得CPU的时间越多。对大多数应用来说，我们最好是不要改变其优先级值。</p>
<p>线程被永久堵塞在一个等待进入同步块的状态。Java的同步代码区是导致线程饥饿的重要因素。Java的同步代码块并不会保证进入它的线程的先后顺序。这就意味着理论上存在一个或者多个线程在试图进入同步代码区时永远被堵塞着，因为其他线程总是不断优于他获得访问权，导致它一直得到不到CPU运行机会被“饥饿致死”。</p>
<p>线程在等待一个本身也处于永久等待完成的对象。如果多个线程处在<code>wait()</code>方法执行上，而对其调用<code>notify()</code>不会保证哪一个线程会获得唤醒，任何线程都有可能处于继续等待的状态。因此存在这样一个风险：一个等待线程从来得不到唤醒，因为其他等待线程总是能被获得唤醒。</p>
<p>为了解决线程“饥饿”的问题，我们可以使用锁实现公平性。</p>
<h2 id="锁的可重入性">锁的可重入性</h2>
<p>我们知道当线程请求一个由其它线程持有锁的对象时，该线程会阻塞，但是当线程请求由自己持有锁的对象时，是否可以成功呢？答案是可以成功的，成功的保障就是线程锁的“可重入性”。<br>
“可重入”意味着自己可以再次获得自己的内部锁，而不需要阻塞。如下：</p>
<pre><code class="language-java">public class Father {
    public synchronized void method(){
        //do something
    }
}
public class Child extends Father{
    public synchronized void method(){
        //do something 
        super.method();
    }
}
</code></pre>
<p>如果所是不可重入的，上面的代码就会死锁，因为调用child的method(),首先会获取父类Father的内置锁然后获取Child的内置锁，当调用父类的方法时，需要再次后去父类的内置锁，如果不可重入，可能会陷入死锁。</p>
<p>java多线程的可重入性的实现是通过每个锁关联一个请求计算和一个占有它的线程，当计数为0时，认为该锁是没有被占有的，那么任何线程都可以获得该锁的占有权。当某一个线程请求成功后，JVM会记录该锁的持有线程 并且将计数设置为1，如果这时其他线程请求该锁时则必须等待。当该线程再次请求请求获得锁时，计数会+1；当占有线程退出同步代码块时，计数就会-1，直到为0时，释放该锁。这时其他线程才有机会获得该锁的占有权。</p>
<ul>
<li>ReentrantLock：一个可重入的互斥锁，为lock接口的主要实现。</li>
<li>ReadWriteLock：ReadWriteLock 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。</li>
<li>ReentrantReadWriteLock：可重入读写锁</li>
<li>Semaphore：一个计数信号量。</li>
<li>Condition:锁的关联条件，目的是允许线程获取锁并且查看等待的某一个条件是否满足。</li>
<li>CyclicBarrier：一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java synchronized]]></title>
        <id>http://goroyal.github.io/post/java-synchronized/</id>
        <link href="http://goroyal.github.io/post/java-synchronized/">
        </link>
        <updated>2020-08-02T09:32:20.000Z</updated>
        <content type="html"><![CDATA[<p>synchronized，我们谓之锁，主要用来给方法、代码块加锁。当某个方法或者代码块使用synchronized时，那么在同一时刻至多仅有有一个线程在执行该段代码。当有多个线程访问同一对象的加锁方法/代码块时，同一时间只有一个线程在执行，其余线程必须要等待当前线程执行完之后才能执行该代码段。但是，其余线程是可以访问该对象中的非加锁代码块的。</p>
<p>synchronized主要包括两种方法：synchronized 方法、synchronized 代码块。</p>
<p>synchronized 方法通过在方法声明中加入 synchronized关键字来声明 synchronized 方法。如：</p>
<pre><code class="language-java">public synchronized void getResult();
</code></pre>
<p>synchronized方法控制对类成员变量的访问。它是如何来避免类成员变量的访问控制呢？我们知道方法使用了synchronized关键字表明该方法已加锁，在任一线程在访问改方法时都必须要判断该方法是否有其他线程在“独占”。每个类实例对应一个把锁，每个synchronized方法都必须调用该方法的类实例的锁方能执行，否则所属线程阻塞，方法一旦执行，就独占该锁，直到从该方法返回时才将锁释放，被阻塞的线程方能获得该锁。</p>
<p>其实synchronized方法是存在缺陷的，如果我们将一个很大的方法声明为synchronized将会大大影响效率的。如果多个线程在访问一个synchronized方法，那么同一时刻只有一个线程在执行该方法，而其他线程都必须等待，但是如果该方法没有使用synchronized，则所有线程可以在同一时刻执行它，减少了执行的总时间。所以如果我们知道一个方法不会被多个线程执行到或者说不存在资源共享的问题，则不需要使用synchronized关键字。但是如果一定要使用synchronized关键字，那么我们可以synchronized代码块来替换synchronized方法。</p>
<p>synchronized代码块所起到的作用和synchronized方法一样，只不过它使临界区变的尽可能短了，换句话说：它只把需要的共享数据保护起来，其余的长代码块留出此操作。语法如下：</p>
<pre><code class="language-java">synchronized(object) {  
    //允许访问控制的代码  
}
</code></pre>
<p>如果我们需要以这种方式来使用synchronized关键字,那么必须要通过一个对象引用来作为参数,通常这个参数我们常使用为this.</p>
<pre><code class="language-java">synchronized (this) {
    //允许访问控制的代码 
}
</code></pre>
<p>对于synchronized(this)有如下理解：</p>
<ul>
<li>当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。</li>
<li>然而，当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问object中的非synchronized(this)同步代码块。</li>
<li>尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其他synchronized(this)同步代码块得访问将被阻塞。</li>
<li>第三个例子同样适用其他同步代码块。也就是说，当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。结果，其他线程对该object对象所有同步代码部分的访问都将被暂时阻塞。</li>
<li>以上规则对其他对象锁同样适用</li>
</ul>
<p>Java中每一个对象都可以作为锁，它主要体现在下面三个方面：</p>
<ul>
<li>对于同步方法，锁是当前实例对象。</li>
<li>对于同步方法块，锁是Synchonized括号里配置的对象。</li>
<li>对于静态同步方法，锁是当前对象的Class对象。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[常用的Git命令]]></title>
        <id>http://goroyal.github.io/post/git-commands/</id>
        <link href="http://goroyal.github.io/post/git-commands/">
        </link>
        <updated>2020-08-02T09:21:54.000Z</updated>
        <content type="html"><![CDATA[<p>配置账号信息</p>
<pre><code class="language-shell">git config --global user.name &quot;your username&quot;
git config --global user.email &quot;your email&quot;
</code></pre>
<p>查看配置相关的信息</p>
<pre><code class="language-shell">git config --list # 查看配置的信息
git help config # 获取帮助信息
</code></pre>
<p>配置自动换行</p>
<pre><code class="language-shell">git config --global core.autocrlf input # 提交到git时是否自动将换行符转换为lf
</code></pre>
<p>配置密钥</p>
<pre><code class="language-shell">ssh-keygen -t rsa -C &quot;your email&quot; # 生成密钥
ssh -T git@github.com # 测试是否成功
</code></pre>
<p>新建仓库</p>
<pre><code class="language-shell">git init # 初始化本地仓库
git clone &lt;url&gt; # 克隆远程版本库
git add –all # 添加所有文件到暂存区（stage，index）
git status # 查看当前git状态
git remote add origin https://github.com/freshdgq/test.git # 关联到远程仓库地址
git push -u origin master # 第一次推送master分支的所有内容
</code></pre>
<p>修改和提交</p>
<pre><code class="language-shell">git status # 查看git当前状态
git diff # 查看改动后和改动前的不同之处
git add . # 跟踪所有改动过的文件
git add &lt;file&gt; # 跟踪指定的文件
git mv &lt;old&gt; &lt;new&gt; # 文件改名
git rm &lt;file&gt; # 删除指定文件
git rm --cached &lt;file&gt; # 停止跟踪文件但不删除
git commit -m &quot;message&quot; # 提交修改的文件到当前分支
git commit --amend # 修改最后一次提交
</code></pre>
<p>状态与版本处理</p>
<pre><code class="language-shell">git log # 查看提交的历史记录
git log -p &lt;file&gt; # 查看指定文件的提交记录
git blame &lt;file&gt; # 以列表方式查看指定文件的提交历史
git reset --hard HEAD  # 撤销工作目录中所有未提交文件的修改内容
git checkout HEAD &lt;file&gt; # 撤销指定的未提交文件的修改内容
git revert &lt;commit&gt; 撤销指定的提交
git reset --hard HEAD^ # 回退本地分支到上一个版本
git reset --hard HEAD~n # 回退本地分支到上n个版本
git checkout – readme.txt # 把readme.txt文件在工作区的修改全部撤销
</code></pre>
<p>分支与标签处理</p>
<pre><code class="language-shell">git branch # 查看本地所有分支
git checkout &lt;branch/tag&gt; # 切换到指定分支或标签

git branch &lt;new-branch&gt; # 创建新分支
git checkout -b &lt;new-branch&gt; # 创建并切换到新分支
git branch -d &lt;branch&gt; # 删除本地分支

git merge &lt;branch&gt; # 合并指定分支到当前分支
git rebase &lt;branch&gt; # 衍合指定分支到当前分支

git tag # 列出所有本地标签
git tag &lt;tagname&gt; # 基于最新提交创建标签
git tag -d &lt;tagname&gt; # 删除标签
</code></pre>
<p>本地远程</p>
<pre><code class="language-shell">git remote # 获得远程库列表
git remote v # 查看远程版本库信息
git remote show &lt;remote&gt; # 查看指定远程版本库信息
git remote add &lt;remote&gt;&lt;url&gt; # 添加远程版本库
git remote rm &lt;name&gt; # 删除对应的远程库
git branch -u origin/master master # 本地跟踪远程

git fetch &lt;remote&gt; # 从远程库获取代码
git pull &lt;remote&gt;&lt;branch&gt; # 拉取远程指定分支代码并快速合并
git push &lt;remote&gt;&lt;branch&gt; # 推送代码到远程指定分支并快速合并
git push &lt;remote&gt;:&lt;branch/tag-name&gt; # 删除远程分支或标签
git push --tags # 上传所有标签

git pull origin master # 从远程的master分支拉取代码到本地
git push origin master # 推送最新修改到远程的主分支
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[网页里面引起脚本执行的方式]]></title>
        <id>http://goroyal.github.io/post/execute-script-in-web-page/</id>
        <link href="http://goroyal.github.io/post/execute-script-in-web-page/">
        </link>
        <updated>2020-08-02T09:16:09.000Z</updated>
        <content type="html"><![CDATA[<p>在当前页面的执行环境里执行脚本的方式：</p>
<ul>
<li>直接嵌入<code>&lt;script&gt;</code>代码块</li>
<li>通过<code>&lt;script src=...&gt;</code>加载远程代码</li>
<li>在各种HTML和CSS参数里通过<code>javascript:URL</code>触发调用</li>
<li>CSS <code>expression(...)</code>和某些浏览器里的XBL绑定</li>
<li>事件处理器（Event Handlers），譬如onclick、onerror、onload等</li>
<li>定时器Timers（setTimeout，setInterval）</li>
<li><code>eval(...)</code>调用</li>
</ul>
<p>表面上这些方法组合起来使用也很正常，但往往会造成极其难以预料的危险解析链传递。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java包装类的比较]]></title>
        <id>http://goroyal.github.io/post/java-baozhuang-class/</id>
        <link href="http://goroyal.github.io/post/java-baozhuang-class/">
        </link>
        <updated>2020-07-20T11:56:18.000Z</updated>
        <content type="html"><![CDATA[<h2 id="boolean">Boolean</h2>
<p><code>Boolean</code>内部维护了两个常量：</p>
<pre><code class="language-Java">public static final Boolean TRUE = new Boolean(true);
public static final Boolean FALSE = new Boolean(false);
</code></pre>
<p>所以对于<code>Boolean a = true; Boolean b = true;</code>，<code>a == b</code>是得到true的。</p>
<h2 id="integer">Integer</h2>
<p><code>Integer</code>对一段范围内的数字有个缓存：IntegerCache.low ~ IntegerCache.high<br>
如果数字在这个范围内，两个integer <code>==</code>是返回true的；否则就会new一个对象返回，肯定是不相等的。<br>
<code>IntegerCache</code>的low是固定死的-128，high默认127，可以通过这个配置修改<code>-XX:AutoBoxCacheMax</code>。</p>
<h2 id="short-long">Short、Long</h2>
<p>和Integer差不多，但是它们的high是固定的127。</p>
<h2 id="参考">参考</h2>
<p><a href="https://github.com/aCoder2013/blog/issues/14">Java原生类型包装类初解析</a></p>
]]></content>
    </entry>
</feed>